# Tree-Based Models

## ðŸŒ³ Overview

This module covers machine learning models that use hierarchical decision structures to perform classification and regression. Emphasis is on interpretability, performance, and ensemble improvements.

---

## ðŸŽ¯ Objectives

* Build and interpret **decision trees**.
* Evaluate model complexity, pruning, and overfitting.
* Apply **Random Forests** for improved stability and performance.
* Train **Gradient Boosting Models** for high-accuracy predictions.

---

## ðŸ›  Methods Covered

* Decision Tree Classifier & Regression Trees
* Random Forests (Bagging Ensembles)
* Gradient Boosted Trees (e.g., XGBoost, LightGBM)

---

## ðŸ“Œ Key Evaluation Metrics

* Confusion matrices
* ROC/AUC & precision-recall measures
* Feature importance interpretation

---

## Run

To run the script, download the `HMEQ_Loss.csv` file from the `\data` folder and store it alongside the `Pasaye_Assignment_2.py` script.

---

## Contact me

If you have any questions or collaboration inquiries, feel free to contact [Joshua Pasaye](https://github.com/jep9731/).
